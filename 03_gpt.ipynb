{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control system\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 7.19Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:00, 1.18Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 8.33Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [20:43, 401kit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.35Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 1.45Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:01, 1.00Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#the AI itself\n",
    "# gpt2.download_gpt2(\n",
    "#     model_name=\"124M\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name=\"124M\", reuse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do this in terninal first\n",
    "mkdir checkpoint\n",
    "cp -r models/124M checkpoint/run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good moring good sir, do thou wish to drink some tea. But I would rather eat butter, and not a little butter. Perhaps you would like me to sit in my kitchen, and watch your own money. I am well aware of the need for tea, and I think you should be able to tell me what you think. Perhaps you would like me to give you a second hand. Farewell, if you desire. Miss Young: I do not see how that will go. It is my pleasure. I shall take your invitation. The maid is now gone, and I need not to go forward. I must return, if I am to make any further inquiries. Good, young gentleman, you have not been very kind to me lately, but I hope you will not mind this. We shall go to the cottage, and I shall pay you a visit. I am now ready to go home. You must tell me if you are ready to return. I will be gentle. Cheer me on, and take a little supper. The mistress had not entered the house since I left. Madame Gaudin: I have not a coach, and my brother will be a little late. I am going to our country for a week, and will give you a coffee. If you please, I will make a few remarks on your health. I am glad you are well. I will get you a nice dinner, and let you have a little tea. Madame Gaudin: I am sorry to say that I am not a very cheerful man. I had thought I had healed properly. I suppose you are rather hot, and have now lost both your body and mind. I have been thinking about your health. If you would still allow me to have a little tea, I would say enough. But I am not so much afraid of the cold that I really am not very nice to you. I hope you will not think of it as much as I do. I hope you will see that I am not very kind to you. I hope you shall think of it in such a way that you will be able to have a good conversation with me. This will be quite a pleasant topic. Madame Gaudin: Come about now. I shall see you soon. Let us go home. Miss Young: I have no time for this. I will return to the house. I am glad you are quite well. I hope you will be very happy. I am going to see you soon. I will bring you a few things. Madam Gaudin: I am sorry to say that I have been very lately. I should not have wanted to take the afternoon off. I am glad you are well. I hope you will be very happy. I will have your letter. I am very sorry to hear that you have not read it as to your health. I must leave it to you to decide whether I will come to you. I am very glad that you are quite well. I am glad that you are very kind to me. I hope you will be very happy. I made a mistake in putting your letter on the table. It was rather a nuisance. But I shall decide to take it. Madam Gaudin: Don't come in. I am afraid you will not think of it as much as I do. I have not been quite well. I had made a mistake in putting your letter on the table. I should have been looking forward to a big dinner. But I thought you might have thought of it that way. I was quite glad you did not think that way. An ugly picture of me. I had thought I had healed well. I should not have looked so much as I did. I would have wanted a little better clothes, but I thought I had healed well on the way home. I am very glad you are quite well. I hope you will be very happy. I will take your letter next day. But I don't know how to take your letter. I have already taken my letter. I am very sorry to hear that. I did not realise how much better it was. I could not help it. I really should have taken two or three less pieces of it. I think I should have put them in the cupboard. I must have put them in a drawer now. But I did not. I was very embarrassed. I should have had a little more time to get them back. I would have given it to the maid. Perhaps you would have let me take your letter. I did not think you would have thought so. I really should have taken it. No, I did not. I am sorry to hear that. I was so sorry to see that you were so much better. I should not have taken your letter. I do not know how to take this letter. I have not got it in my hand yet. I did not suppose that I could take the letter. I was sorry I had taken your letter. I did not think I could take it. I\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(session, \n",
    "              model_name=\"124M\",\n",
    "              prefix=\"Good moring good sir, do thou wish to drink some tea.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt2\u001b[39m.\u001b[39;49mfinetune(\n\u001b[1;32m      2\u001b[0m     session2,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mshakespeare.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m124M\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     steps\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \u001b[39m#control how many time the AI trains itself\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m     run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mshakespeare\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py:198\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m multi_gpu:\n\u001b[1;32m    196\u001b[0m     gpus \u001b[39m=\u001b[39m get_available_gpus()\n\u001b[0;32m--> 198\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmodel(hparams\u001b[39m=\u001b[39;49mhparams, X\u001b[39m=\u001b[39;49mcontext, gpus\u001b[39m=\u001b[39;49mgpus, reuse\u001b[39m=\u001b[39;49mreuse)\n\u001b[1;32m    199\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\n\u001b[1;32m    200\u001b[0m     input_tensor\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m    201\u001b[0m         labels\u001b[39m=\u001b[39mcontext[:, \u001b[39m1\u001b[39m:], logits\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m][:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m    203\u001b[0m tf_sample \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39msample_sequence(\n\u001b[1;32m    204\u001b[0m     hparams\u001b[39m=\u001b[39mhparams,\n\u001b[1;32m    205\u001b[0m     length\u001b[39m=\u001b[39msample_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m    209\u001b[0m     top_k\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py:188\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    185\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    186\u001b[0m batch, sequence \u001b[39m=\u001b[39m shape_list(X)\n\u001b[0;32m--> 188\u001b[0m wpe \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mget_variable(\u001b[39m'\u001b[39;49m\u001b[39mwpe\u001b[39;49m\u001b[39m'\u001b[39;49m, [hparams\u001b[39m.\u001b[39;49mn_ctx, hparams\u001b[39m.\u001b[39;49mn_embd],\n\u001b[1;32m    189\u001b[0m                      initializer\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mrandom_normal_initializer(stddev\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m))\n\u001b[1;32m    190\u001b[0m wte \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mwte\u001b[39m\u001b[39m'\u001b[39m, [hparams\u001b[39m.\u001b[39mn_vocab, hparams\u001b[39m.\u001b[39mn_embd],\n\u001b[1;32m    191\u001b[0m                      initializer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mrandom_normal_initializer(stddev\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m))\n\u001b[1;32m    192\u001b[0m past_length \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m past \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m tf\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mpast)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:1565\u001b[0m, in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_variable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_variable\u001b[39m(name,\n\u001b[1;32m   1551\u001b[0m                  shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1563\u001b[0m                  synchronization\u001b[39m=\u001b[39mVariableSynchronization\u001b[39m.\u001b[39mAUTO,\n\u001b[1;32m   1564\u001b[0m                  aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE):\n\u001b[0;32m-> 1565\u001b[0m   \u001b[39mreturn\u001b[39;00m get_variable_scope()\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1566\u001b[0m       _get_default_variable_store(),\n\u001b[1;32m   1567\u001b[0m       name,\n\u001b[1;32m   1568\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1569\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1570\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1571\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1572\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1573\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1574\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1575\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1576\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1577\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1578\u001b[0m       custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1579\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1580\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1581\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:1275\u001b[0m, in \u001b[0;36mVariableScope.get_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1274\u001b[0m   dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n\u001b[0;32m-> 1275\u001b[0m \u001b[39mreturn\u001b[39;00m var_store\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1276\u001b[0m     full_name,\n\u001b[1;32m   1277\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1278\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1279\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1280\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1281\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m   1282\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1283\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1284\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1285\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1286\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1287\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1288\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1289\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1290\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1291\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:520\u001b[0m, in \u001b[0;36m_VariableStore.get_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    518\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_getter(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom_getter_kwargs)\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[39mreturn\u001b[39;00m _true_getter(\n\u001b[1;32m    521\u001b[0m       name,\n\u001b[1;32m    522\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    523\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    524\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    525\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    526\u001b[0m       reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    527\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    528\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    529\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    530\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    531\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    532\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    533\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    534\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    535\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:473\u001b[0m, in \u001b[0;36m_VariableStore.get_variable.<locals>._true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars:\n\u001b[1;32m    468\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    469\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mNo partitioner was provided, but a partitioned version of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mvariable was found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0. Perhaps a variable of the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname was already created with partitioning?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 473\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_variable(\n\u001b[1;32m    474\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    475\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    476\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    477\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    478\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    479\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    480\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    481\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    482\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    483\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    484\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    485\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    486\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    487\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:831\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# ResourceVariables don't have an op associated with so no traceback\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(var, resource_variable_ops\u001b[39m.\u001b[39mResourceVariable):\n\u001b[0;32m--> 831\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m    832\u001b[0m tb \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mtraceback[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    833\u001b[0m \u001b[39m# Throw away internal tf entries and only take a few lines. In some\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39m# cases the traceback can be longer (e.g. if someone uses factory\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m# functions to create variables) so we take more than needed in the\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[39m# default case.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    \"shakespeare.txt\",\n",
    "    model_name=\"124M\",\n",
    "    steps=100, #control how many time the AI trains itself\n",
    "    run_name=\"shakespeare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 10:49:05.682455: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: Could not find variable model/h5/attn/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/attn/c_proj/w)\n",
      "\t [[{{node sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp}}]]\n",
      "2024-11-25 10:49:05.682535: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at resource_variable_ops.cc:722 : NOT_FOUND: Container localhost does not exist. (Could not find resource: localhost/model/wte)\n",
      "2024-11-25 10:49:05.682786: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at resource_variable_ops.cc:722 : NOT_FOUND: Container localhost does not exist. (Could not find resource: localhost/model/wpe)\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp' defined at (most recent call last):\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    File \"/var/folders/k5/nh1z4lzs5qj_jk4cmjqwyc080000gr/T/ipykernel_97838/387187629.py\", line 1, in <module>\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py\", line 462, in generate\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 51, in step\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 203, in model\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 156, in block\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 141, in attn\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\nNode: 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp'\nCould not find variable model/h5/attn/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/attn/c_proj/w)\n\t [[{{node sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp}}]]\n\nOriginal stack trace for 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp':\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n  File \"/var/folders/k5/nh1z4lzs5qj_jk4cmjqwyc080000gr/T/ipykernel_97838/387187629.py\", line 1, in <module>\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py\", line 462, in generate\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 51, in step\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 203, in model\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 156, in block\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 141, in attn\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/array_ops.py\", line 199, in reshape\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8758, in reshape\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 778, in _apply_op_helper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 551, in _ExtractInputsAndAttrs\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 713, in convert_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 2331, in _dense_var_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1577, in _dense_var_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 629, in value\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 813, in _read_variable_op\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 803, in read_and_set_handle\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 548, in read_variable_op\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 2682, in _create_op_internal\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 1177, in from_node_def\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1403\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1386\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1479\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1480\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Could not find variable model/h5/attn/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/attn/c_proj/w)\n\t [[{{node sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt2\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      2\u001b[0m     session2,\n\u001b[1;32m      3\u001b[0m     prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWould you like some tea good sir?\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mshakespeare\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py:479\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[1;32m    477\u001b[0m     out \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun(output)\n\u001b[1;32m    478\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     out \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(output, feed_dict\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    480\u001b[0m             context: batch_size \u001b[39m*\u001b[39;49m [context_tokens]\n\u001b[1;32m    481\u001b[0m         })\n\u001b[1;32m    482\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m    483\u001b[0m     generated \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    973\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    974\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1216\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1396\u001b[0m                        run_metadata)\n\u001b[1;32m   1397\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/client/session.py:1421\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[1;32m   1417\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1418\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1419\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1420\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1421\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp' defined at (most recent call last):\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    File \"/var/folders/k5/nh1z4lzs5qj_jk4cmjqwyc080000gr/T/ipykernel_97838/387187629.py\", line 1, in <module>\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py\", line 462, in generate\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 51, in step\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 203, in model\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 156, in block\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 141, in attn\n    File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\nNode: 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp'\nCould not find variable model/h5/attn/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/attn/c_proj/w)\n\t [[{{node sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp}}]]\n\nOriginal stack trace for 'sample_sequence_2/model/h5/attn/c_proj/Reshape_1/ReadVariableOp':\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n  File \"/var/folders/k5/nh1z4lzs5qj_jk4cmjqwyc080000gr/T/ipykernel_97838/387187629.py\", line 1, in <module>\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py\", line 462, in generate\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/sample.py\", line 51, in step\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 203, in model\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 156, in block\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 141, in attn\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/array_ops.py\", line 199, in reshape\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8758, in reshape\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 778, in _apply_op_helper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 551, in _ExtractInputsAndAttrs\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 713, in convert_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 2331, in _dense_var_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1577, in _dense_var_to_tensor\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 629, in value\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 813, in _read_variable_op\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 803, in read_and_set_handle\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 548, in read_variable_op\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\", line 796, in _apply_op_helper\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 2682, in _create_op_internal\n  File \"/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 1177, in from_node_def\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix=\"Would you like some tea good sir?\",\n",
    "    run_name=\"shakespeare\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
